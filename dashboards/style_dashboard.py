#!/usr/bin/env python3
"""
Interactive dashboard for exploring stylistic signals in the conversation corpus.

This tool loads the snippets generated by `utils/style_filter.py`, derives lightweight
tags using the GraphRAG tagging utilities, embeds the target assistant messages, and
projects them via t-SNE for visual inspection. It also surfaces common n-grams and
high-scoring free-form style annotations so that annotators can quickly audit the
dataset's stylistic coverage.
"""

from __future__ import annotations

import argparse
import json
import inspect
import random
import re
from collections import Counter
from pathlib import Path
from typing import Any, Dict, Iterable, List, Sequence, Tuple

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from dash import Dash, Input, Output, dcc, html, dash_table
from sklearn.decomposition import TruncatedSVD
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer
from sklearn.manifold import TSNE

# Ensure the repo root is on sys.path so we import the local graphrag package
REPO_ROOT = Path(__file__).resolve().parents[1]
if REPO_ROOT.exists():
    import sys

    repo_root_str = str(REPO_ROOT)
    if repo_root_str not in sys.path:
        sys.path.insert(0, repo_root_str)

try:  # Prefer local graphrag config, but fall back gracefully
    from graphrag.config import EmbeddingConfig  # type: ignore
except (ImportError, AttributeError):  # pragma: no cover - optional dependency
    EmbeddingConfig = None  # type: ignore
from graphrag.tagging import TagGenerator


DEFAULT_SNIPPETS_PATH = Path("data/merged/all_conversations_style_selected.json")
DEFAULT_ANNOTATIONS_PATH = Path("data/merged/style_annotations.jsonl")
TOKEN_RE = re.compile(r"[a-z0-9']+")
STOPWORDS = set(ENGLISH_STOP_WORDS)

CATEGORICAL_FIELDS = [
    "tone",
    "formality",
    "information_content",
    "sentiment",
    "friendliness",
    "purpose",
    "complexity",
    "resolution",
    "engagement",
    "primary_content_type",
    "domain",
    "urgency",
    "response_depth",
    "dominant_time_bucket",
]

NUMERIC_FIELDS = [
    "style_score",
    "emoji_density",
    "question_density",
    "assistant_turn_ratio",
    "assistant_avg_word_count",
    "user_turn_ratio",
    "duration_hours",
    "message_count",
]


class TextEmbedder:
    """
    Thin wrapper that either delegates to SentenceTransformerEmbedder or falls back to TF-IDF.
    """

    def __init__(self, backend: str, model_name: str, seed: int):
        self.backend = backend
        self.model_name = model_name
        self.seed = seed
        self._embedder = None
        self._vectorizer: TfidfVectorizer | None = None
        self._reducer: TruncatedSVD | None = None
        if self.backend == "tfidf":
            self._vectorizer = TfidfVectorizer(
                max_features=5000,
                ngram_range=(1, 2),
                stop_words="english",
            )
            self._reducer = TruncatedSVD(
                n_components=256, random_state=self.seed
            )

    def _ensure_sentence_transformer(self):
        if self._embedder is None:
            try:
                from graphrag.embedding import SentenceTransformerEmbedder
            except Exception as exc:  # pragma: no cover - import-time failures
                raise RuntimeError(
                    "Failed to import sentence-transformers. Install the dependency "
                    "or run with --embedding-backend tfidf."
                ) from exc
            if EmbeddingConfig is not None:
                config = EmbeddingConfig(model_name=self.model_name)
            else:  # pragma: no cover - rare fallback
                class _TempEmbeddingConfig:
                    def __init__(self, model_name: str):
                        self.model_name = model_name
                        self.device = None
                        self.batch_size = 32
                        self.normalize_embeddings = True

                config = _TempEmbeddingConfig(self.model_name)
            self._embedder = SentenceTransformerEmbedder(config)
        return self._embedder

    def embed(self, texts: Sequence[str]) -> np.ndarray:
        text_list = list(texts)
        if not text_list:
            return np.zeros((0, 0), dtype=np.float32)

        if self.backend == "sentence-transformers":
            embedder = self._ensure_sentence_transformer()
            return embedder.embed(text_list)

        if not self._vectorizer or not self._reducer:
            raise RuntimeError("TF-IDF backend was not initialised.")

        matrix = self._vectorizer.fit_transform(text_list)
        reduced = self._reducer.fit_transform(matrix)
        return reduced.astype(np.float32)


def _log(message: str) -> None:
    print(f"[style-dashboard] {message}")


def load_json(path: Path) -> List[Dict[str, Any]]:
    _log(f"Loading snippets from {path}")
    with path.open("r", encoding="utf-8") as handle:
        return json.load(handle)


def load_jsonl(path: Path) -> List[Dict[str, Any]]:
    if not path.exists():
        return []
    _log(f"Loading style annotations from {path}")
    records: List[Dict[str, Any]] = []
    with path.open("r", encoding="utf-8") as handle:
        for line in handle:
            line = line.strip()
            if not line:
                continue
            try:
                records.append(json.loads(line))
            except json.JSONDecodeError:
                continue
    return records


def choose_indices(total: int, limit: int, seed: int) -> List[int]:
    indices = list(range(total))
    if limit <= 0 or limit >= total:
        return indices
    rng = random.Random(seed)
    rng.shuffle(indices)
    chosen = sorted(indices[:limit])
    _log(f"Sampled {len(chosen)} of {total} snippets for visualization")
    return chosen


def extract_text_fields(messages: Sequence[Dict[str, Any]]) -> Tuple[str, str, str]:
    if not messages:
        return "", "", ""

    assistant_text = ""
    for msg in reversed(messages):
        if msg.get("role") == "assistant" and msg.get("content"):
            assistant_text = msg["content"]
            break
    if not assistant_text:
        assistant_text = messages[-1].get("content", "") or ""

    context_lines = [
        f"{msg.get('role', 'unknown')}: {msg.get('content', '')}"
        for msg in messages[:-1]
        if msg.get("content")
    ]
    full_lines = [
        f"{msg.get('role', 'unknown')}: {msg.get('content', '')}"
        for msg in messages
        if msg.get("content")
    ]
    return assistant_text, "\n".join(context_lines), "\n".join(full_lines)


def attach_tags(
    tagger: TagGenerator | None, snippet: Dict[str, Any]
) -> Dict[str, Any]:
    if tagger is None:
        return {}

    annotation, _ = tagger.annotate_conversation(snippet)
    content_type = annotation.content_type or []
    return {
        "tone": annotation.tone or "neutral",
        "formality": annotation.formality or "neutral",
        "information_content": annotation.information_content or "conversational",
        "sentiment": annotation.sentiment or "neutral",
        "friendliness": annotation.friendliness or "neutral",
        "purpose": annotation.purpose or "general",
        "complexity": annotation.complexity or "intermediate",
        "resolution": annotation.resolution or "unknown",
        "engagement": annotation.engagement or "medium_interaction",
        "primary_content_type": content_type[0] if content_type else "text_only",
        "content_type": ", ".join(content_type) if content_type else "text_only",
        "domain": annotation.domain or "general",
        "urgency": annotation.urgency or "normal",
        "response_depth": annotation.response_depth or "brief",
        "dominant_time_bucket": annotation.dominant_time_bucket or "unknown",
        "emoji_density": float(annotation.emoji_density or 0.0),
        "question_density": float(annotation.question_density or 0.0),
        "assistant_turn_ratio": float(annotation.assistant_turn_ratio or 0.0),
        "assistant_avg_word_count": float(annotation.assistant_avg_word_count or 0.0),
        "user_turn_ratio": float(annotation.user_turn_ratio or 0.0),
        "duration_hours": float(annotation.duration_hours or 0.0),
        "message_count": int(annotation.message_count or 0),
    }


def build_records(
    snippets: Sequence[Dict[str, Any]],
    indices: Sequence[int],
    tagger: TagGenerator | None,
) -> List[Dict[str, Any]]:
    records: List[Dict[str, Any]] = []
    for local_idx, snippet_idx in enumerate(indices):
        snippet = snippets[snippet_idx]
        openai_messages = snippet.get("openai_messages", [])
        assistant_text, context_text, conversation_text = extract_text_fields(
            openai_messages
        )

        record: Dict[str, Any] = {
            "row_id": local_idx,
            "snippet_index": snippet_idx,
            "assistant_text": assistant_text,
            "context_text": context_text,
            "conversation_text": conversation_text,
            "style_score": float(snippet.get("style_score", 0.0)),
            "parent_conversation_index": snippet.get("parent_conversation_index"),
            "parent_message_index": snippet.get("parent_message_index"),
            "first_message_timestamp": snippet.get("first_message_timestamp"),
            "last_message_timestamp": snippet.get("last_message_timestamp"),
            "num_messages": len(openai_messages),
            "recipients": ", ".join(snippet.get("recipients") or []),
            "chat_type": snippet.get("chat_type") or "unknown",
        }
        record.update(attach_tags(tagger, snippet))
        records.append(record)
    return records


def compute_tsne(embeddings: np.ndarray, perplexity: float, seed: int) -> np.ndarray:
    if embeddings.size == 0:
        raise ValueError("No embeddings to project.")

    max_perplexity = max(5, min(perplexity, (embeddings.shape[0] - 1) / 3))
    _log(
        f"Running t-SNE on {embeddings.shape[0]} vectors (perplexity={max_perplexity:.1f})"
    )
    tsne_kwargs = dict(
        n_components=2,
        perplexity=max_perplexity,
        metric="cosine",
        init="pca",
        random_state=seed,
    )
    tsne_params = inspect.signature(TSNE.__init__).parameters
    if "n_iter" in tsne_params:
        tsne_kwargs["n_iter"] = 2000
    elif "max_iter" in tsne_params:
        tsne_kwargs["max_iter"] = 2000
    projector = TSNE(**tsne_kwargs)
    return projector.fit_transform(embeddings)


def clean_text(text: str) -> List[str]:
    tokens = [tok for tok in TOKEN_RE.findall(text.lower()) if tok]
    return tokens


def build_ngram_summary(texts: Iterable[str], top_k: int = 20) -> Dict[int, List[Dict[str, Any]]]:
    summaries: Dict[int, List[Dict[str, Any]]] = {}
    for n in (1, 2, 3):
        counter: Counter[str] = Counter()
        for text in texts:
            tokens = clean_text(text or "")
            if not tokens or len(tokens) < n:
                continue
            for i in range(len(tokens) - n + 1):
                gram_tokens = tokens[i : i + n]
                if n == 1 and gram_tokens[0] in STOPWORDS:
                    continue
                if n > 1 and all(token in STOPWORDS for token in gram_tokens):
                    continue
                counter[" ".join(gram_tokens)] += 1
        summaries[n] = [
            {"ngram": gram, "count": count} for gram, count in counter.most_common(top_k)
        ]
    return summaries


def create_score_hist(df: pd.DataFrame) -> go.Figure:
    fig = px.histogram(
        df,
        x="style_score",
        nbins=40,
        marginal="box",
        template="plotly_white",
    )
    fig.update_layout(
        title="Style Score Distribution",
        bargap=0.05,
        height=320,
        margin=dict(l=40, r=20, t=50, b=40),
    )
    return fig


def create_scatter(
    df: pd.DataFrame, color_field: str, score_range: Sequence[float]
) -> go.Figure:
    mask = (df["style_score"] >= score_range[0]) & (df["style_score"] <= score_range[1])
    filtered = df.loc[mask]
    if filtered.empty:
        return go.Figure(
            layout=go.Layout(
                title="No snippets match the current filters",
                template="plotly_white",
            )
        )

    color = color_field if color_field in filtered.columns else "style_score"
    fig = px.scatter(
        filtered,
        x="tsne_x",
        y="tsne_y",
        color=color,
        hover_data={
            "style_score": ":.3f",
            "tone": True,
            "formality": True,
            "assistant_text": True,
        },
        template="plotly_white",
    )
    fig.update_traces(marker=dict(size=9, opacity=0.85))
    fig.update_layout(
        title="t-SNE projection of stylistic embeddings",
        height=600,
        margin=dict(l=30, r=20, t=50, b=40),
    )
    return fig


def create_tag_distribution(df: pd.DataFrame, column: str) -> go.Figure:
    if column not in df.columns:
        return go.Figure(
            layout=go.Layout(title=f"No data for {column}", template="plotly_white")
        )

    counts = (
        df[column]
        .fillna("unknown")
        .value_counts()
        .sort_values(ascending=True)
    )
    fig = go.Figure(
        data=[
            go.Bar(
                x=counts.values,
                y=counts.index,
                orientation="h",
                marker_color="#2563eb",
            )
        ]
    )
    fig.update_layout(
        template="plotly_white",
        title=f"{column.replace('_', ' ').title()} distribution",
        height=340,
        margin=dict(l=100, r=20, t=50, b=40),
    )
    return fig


def create_ngram_figure(
    ngram_summary: Dict[int, List[Dict[str, Any]]], n: int
) -> go.Figure:
    data = ngram_summary.get(n, [])
    if not data:
        return go.Figure(
            layout=go.Layout(title=f"No n-gram data for n={n}", template="plotly_white")
        )
    grams = list(reversed(data))
    fig = go.Figure(
        data=[
            go.Bar(
                x=[item["count"] for item in grams],
                y=[item["ngram"] for item in grams],
                orientation="h",
                marker=dict(color="#10b981"),
            )
        ]
    )
    fig.update_layout(
        title=f"Top {len(data)} {n}-grams",
        template="plotly_white",
        height=500,
        margin=dict(l=200, r=20, t=50, b=40),
    )
    return fig


def prepare_dashboard_data(args: argparse.Namespace) -> Tuple[pd.DataFrame, Dict[int, List[Dict[str, Any]]], pd.DataFrame]:
    snippets = load_json(Path(args.snippets))
    annotations = load_jsonl(Path(args.annotations))
    indices = choose_indices(len(snippets), args.max_snippets, args.seed)
    tagger = None
    if not args.skip_tagging:
        _log("Deriving tagging signals with graphrag.tagging.TagGenerator")
        tagger = TagGenerator(
            timezone_name=args.timezone,
            use_zero_shot=args.use_zero_shot,
            device=args.zero_shot_device,
        )
    records = build_records(snippets, indices, tagger)
    if not records:
        raise RuntimeError("No snippets were loaded; cannot start dashboard.")

    df = pd.DataFrame.from_records(records)
    for field in CATEGORICAL_FIELDS:
        if field in df.columns:
            df[field] = df[field].fillna("unknown")
    for field in NUMERIC_FIELDS:
        if field in df.columns:
            df[field] = df[field].fillna(0.0)

    embedder = TextEmbedder(args.embedding_backend, args.embedding_model, args.seed)
    texts = df["assistant_text"].fillna("").tolist()
    embeddings = embedder.embed(texts)
    coords = compute_tsne(embeddings, args.tsne_perplexity, args.seed)
    df["tsne_x"] = coords[:, 0]
    df["tsne_y"] = coords[:, 1]

    ngram_summary = build_ngram_summary(texts, top_k=args.top_ngrams)
    annotations_df = pd.DataFrame(annotations)
    if not annotations_df.empty:
        annotations_df = annotations_df.sort_values("score", ascending=False)
    return df, ngram_summary, annotations_df


def create_dashboard_app(
    df: pd.DataFrame,
    ngram_summary: Dict[int, List[Dict[str, Any]]],
    annotations_df: pd.DataFrame,
) -> Dash:
    score_hist_fig = create_score_hist(df)
    score_min = float(df["style_score"].min())
    score_max = float(df["style_score"].max())
    color_options = [
        field
        for field in ["tone", "formality", "style_score", "primary_content_type", "domain"]
        if field in df.columns
    ]
    default_color = color_options[0] if color_options else "style_score"
    tag_options = [field for field in CATEGORICAL_FIELDS if field in df.columns]
    default_tag = tag_options[0] if tag_options else default_color

    annotations_preview = annotations_df.head(40) if not annotations_df.empty else pd.DataFrame()

    app = Dash(__name__)
    app.title = "ReplAI Style Dashboard"
    app.layout = html.Div(
        [
            html.H1("Conversation Style Dashboard", style={"marginBottom": "0.2rem"}),
            html.P(
                "Explore stylistic clusters, derived tags, and lexical patterns extracted "
                "from the filtered conversation snippets.",
                style={"color": "#475569", "marginTop": 0},
            ),
            html.Div(
                [
                    html.Div(
                        [
                            html.Label("Color by"),
                            dcc.Dropdown(
                                id="color-dropdown",
                                options=[{"label": option.replace("_", " ").title(), "value": option} for option in color_options],
                                value=default_color,
                                clearable=False,
                            ),
                        ],
                        style={"flex": "1", "marginRight": "1rem"},
                    ),
                    html.Div(
                        [
                            html.Label("Style score range"),
                            dcc.RangeSlider(
                                id="score-range",
                                min=score_min,
                                max=score_max,
                                value=[score_min, score_max],
                                tooltip={"placement": "bottom", "always_visible": False},
                                step=0.01,
                            ),
                        ],
                        style={"flex": "2"},
                    ),
                ],
                style={
                    "display": "flex",
                    "flexWrap": "wrap",
                    "gap": "1rem",
                    "marginBottom": "1.5rem",
                },
            ),
            html.Div(
                [
                    dcc.Graph(id="tsne-scatter", figure=create_scatter(df, default_color, [score_min, score_max]), style={"flex": "2"}),
                    html.Div(
                        [
                            dcc.Graph(figure=score_hist_fig, id="score-hist"),
                            html.Label("Tag distribution"),
                            dcc.Dropdown(
                                id="tag-dropdown",
                                options=[{"label": tag.replace("_", " ").title(), "value": tag} for tag in tag_options],
                                value=default_tag,
                                clearable=False,
                                style={"marginBottom": "0.5rem"},
                            ),
                            dcc.Graph(
                                id="tag-distribution",
                                figure=create_tag_distribution(df, default_tag),
                            ),
                        ],
                        style={"flex": "1", "display": "flex", "flexDirection": "column", "gap": "1rem"},
                    ),
                ],
                style={"display": "flex", "flexWrap": "wrap", "gap": "1rem"},
            ),
            html.Div(
                [
                    html.Div(
                        [
                            html.H3("Lexical signals"),
                            dcc.RadioItems(
                                id="ngram-radio",
                                options=[
                                    {"label": "Unigrams", "value": 1},
                                    {"label": "Bigrams", "value": 2},
                                    {"label": "Trigrams", "value": 3},
                                ],
                                value=2,
                                inline=True,
                                style={"marginBottom": "1rem"},
                            ),
                            dcc.Graph(
                                id="ngram-graph",
                                figure=create_ngram_figure(ngram_summary, 2),
                            ),
                        ],
                        style={"flex": "1"},
                    ),
                    html.Div(
                        [
                            html.H3("Top cached style prompts"),
                            html.P(
                                "Highest scoring free-form style annotations cached by utils/style_filter.py",
                                style={"color": "#475569"},
                            ),
                            dash_table.DataTable(
                                id="annotations-table",
                                columns=[
                                    {"name": "Score", "id": "score"},
                                    {"name": "Content", "id": "content"},
                                    {"name": "Conversation", "id": "conversation_index"},
                                    {"name": "Message", "id": "message_index"},
                                ],
                                data=annotations_preview.to_dict("records"),
                                page_size=10,
                                style_cell={
                                    "textAlign": "left",
                                    "whiteSpace": "normal",
                                    "height": "auto",
                                },
                                style_header={"fontWeight": "bold"},
                            )
                            if not annotations_preview.empty
                            else html.Div(
                                "No cached annotations were found.",
                                style={"padding": "1rem", "backgroundColor": "#f1f5f9"},
                            ),
                        ],
                        style={"flex": "1", "padding": "0 1rem"},
                    ),
                ],
                style={"display": "flex", "flexWrap": "wrap", "gap": "1rem", "marginTop": "2rem"},
            ),
        ],
        style={
            "fontFamily": "'Inter', sans-serif",
            "padding": "2rem",
            "backgroundColor": "#ffffff",
            "color": "#0f172a",
        },
    )

    @app.callback(
    Output("tsne-scatter", "figure"),
    Input("color-dropdown", "value"),
    Input("score-range", "value"),
    )
    def update_scatter(color_value: str, score_range: List[float]) -> go.Figure:
        color = color_value or default_color
        slider_range = score_range or [score_min, score_max]
        return create_scatter(df, color, slider_range)

    @app.callback(
        Output("tag-distribution", "figure"),
        Input("tag-dropdown", "value"),
    )
    def update_tag_distribution(selected_tag: str) -> go.Figure:
        tag = selected_tag or default_tag
        return create_tag_distribution(df, tag)

    @app.callback(
        Output("ngram-graph", "figure"),
        Input("ngram-radio", "value"),
    )
    def update_ngrams(selected_n: int) -> go.Figure:
        return create_ngram_figure(ngram_summary, int(selected_n or 2))

    return app


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Launch an interactive dashboard that visualizes stylistic signals."
    )
    parser.add_argument(
        "--snippets",
        type=str,
        default=str(DEFAULT_SNIPPETS_PATH),
        help="Path to the snippets JSON produced by utils/style_filter.py",
    )
    parser.add_argument(
        "--annotations",
        type=str,
        default=str(DEFAULT_ANNOTATIONS_PATH),
        help="Optional JSONL file with cached style annotations.",
    )
    parser.add_argument(
        "--max-snippets",
        type=int,
        default=4000,
        help="Limit the number of snippets to embed for faster startup.",
    )
    parser.add_argument(
        "--embedding-model",
        type=str,
        default="sentence-transformers/all-MiniLM-L6-v2",
        help="SentenceTransformers model (used when embedding-backend=sentence-transformers).",
    )
    parser.add_argument(
        "--embedding-backend",
        choices=["sentence-transformers", "tfidf"],
        default="sentence-transformers",
        help="Embedding provider to use for the scatter plot.",
    )
    parser.add_argument(
        "--tsne-perplexity",
        type=float,
        default=35.0,
        help="Perplexity parameter for t-SNE.",
    )
    parser.add_argument(
        "--top-ngrams",
        type=int,
        default=20,
        help="Number of n-grams to display in the lexical chart.",
    )
    parser.add_argument(
        "--skip-tagging",
        action="store_true",
        help="Skip running graphrag.tagging to speed up startup.",
    )
    parser.add_argument(
        "--use-zero-shot",
        action="store_true",
        help="Enable zero-shot tagging (requires transformers).",
    )
    parser.add_argument(
        "--zero-shot-device",
        type=int,
        default=-1,
        help="Device index for zero-shot classifier (used when --use-zero-shot).",
    )
    parser.add_argument(
        "--timezone",
        type=str,
        default="America/Los_Angeles",
        help="Timezone used for time-of-day tagging buckets.",
    )
    parser.add_argument("--seed", type=int, default=17, help="Random seed.")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="Dashboard host.")
    parser.add_argument("--port", type=int, default=8050, help="Dashboard port.")
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Run Dash in debug mode with live reload.",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    df, ngram_summary, annotations_df = prepare_dashboard_data(args)
    app = create_dashboard_app(df, ngram_summary, annotations_df)
    _log(f"Starting dashboard on http://{args.host}:{args.port}")
    app.run(debug=args.debug, host=args.host, port=args.port)


if __name__ == "__main__":
    main()
